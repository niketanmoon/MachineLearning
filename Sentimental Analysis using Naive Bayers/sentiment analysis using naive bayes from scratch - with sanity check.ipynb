{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Import libraries\n",
    "- ### Note that f1 score and accuracy score is imported only to sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:15.588163Z",
     "iopub.status.busy": "2022-04-09T14:00:15.587558Z",
     "iopub.status.idle": "2022-04-09T14:00:16.565865Z",
     "shell.execute_reply": "2022-04-09T14:00:16.565079Z",
     "shell.execute_reply.started": "2022-04-09T14:00:15.588059Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/niketan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/niketan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/niketan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For tokenization\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# For word lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# For performance evaluation\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:16.567614Z",
     "iopub.status.busy": "2022-04-09T14:00:16.567367Z",
     "iopub.status.idle": "2022-04-09T14:00:19.098527Z",
     "shell.execute_reply": "2022-04-09T14:00:19.097810Z",
     "shell.execute_reply.started": "2022-04-09T14:00:16.567562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the csv file\n",
    "full_dataset = pd.read_csv(\"imdb_master.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used ISO-8859-1 encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:19.099787Z",
     "iopub.status.busy": "2022-04-09T14:00:19.099579Z",
     "iopub.status.idle": "2022-04-09T14:00:19.119154Z",
     "shell.execute_reply": "2022-04-09T14:00:19.118522Z",
     "shell.execute_reply.started": "2022-04-09T14:00:19.099762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the dataframe with 5 entries\n",
    "full_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:19.120850Z",
     "iopub.status.busy": "2022-04-09T14:00:19.120633Z",
     "iopub.status.idle": "2022-04-09T14:00:19.189308Z",
     "shell.execute_reply": "2022-04-09T14:00:19.188509Z",
     "shell.execute_reply.started": "2022-04-09T14:00:19.120825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  100000 non-null  int64 \n",
      " 1   type        100000 non-null  object\n",
      " 2   review      100000 non-null  object\n",
      " 3   label       100000 non-null  object\n",
      " 4   file        100000 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# getting the information on the dataset\n",
    "full_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above exploration we can say that we will need review and label and type as it tells about type of data (but still it is not clear)\n",
    "- We can also confirm from info that there is no null object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exploration for how many values of type and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:19.190808Z",
     "iopub.status.busy": "2022-04-09T14:00:19.190606Z",
     "iopub.status.idle": "2022-04-09T14:00:19.208255Z",
     "shell.execute_reply": "2022-04-09T14:00:19.207356Z",
     "shell.execute_reply.started": "2022-04-09T14:00:19.190784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    75000\n",
       "test     25000\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding type of values in \"type\" column\n",
    "full_dataset.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:19.209766Z",
     "iopub.status.busy": "2022-04-09T14:00:19.209469Z",
     "iopub.status.idle": "2022-04-09T14:00:19.232369Z",
     "shell.execute_reply": "2022-04-09T14:00:19.231600Z",
     "shell.execute_reply.started": "2022-04-09T14:00:19.209738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unsup    50000\n",
       "neg      25000\n",
       "pos      25000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding type of values in \"label\" column\n",
    "full_dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From above we can say that \n",
    "- `type` - `train` and `test` as type of data\n",
    "- `label` - `unsup`, `neg` and `pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- Remove the unwanted data\n",
    "    - dropping the columns - `Unnamed and file`\n",
    "    - dropping the rows that has label= `unsup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:19.233771Z",
     "iopub.status.busy": "2022-04-09T14:00:19.233437Z",
     "iopub.status.idle": "2022-04-09T14:00:19.241969Z",
     "shell.execute_reply": "2022-04-09T14:00:19.241065Z",
     "shell.execute_reply.started": "2022-04-09T14:00:19.233740Z"
    }
   },
   "outputs": [],
   "source": [
    "# taking only the useful columns\n",
    "full_dataset = full_dataset.iloc[:, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:19.243358Z",
     "iopub.status.busy": "2022-04-09T14:00:19.243072Z",
     "iopub.status.idle": "2022-04-09T14:00:19.273187Z",
     "shell.execute_reply": "2022-04-09T14:00:19.272142Z",
     "shell.execute_reply.started": "2022-04-09T14:00:19.243317Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping the rows with label = unsup\n",
    "full_dataset = full_dataset[full_dataset.label != \"unsup\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:19.276192Z",
     "iopub.status.busy": "2022-04-09T14:00:19.275587Z",
     "iopub.status.idle": "2022-04-09T14:00:19.290013Z",
     "shell.execute_reply": "2022-04-09T14:00:19.289317Z",
     "shell.execute_reply.started": "2022-04-09T14:00:19.276144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>train</td>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>train</td>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>train</td>\n",
       "      <td>I am amazed at how this movie(and most others ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>train</td>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>train</td>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                             review label\n",
       "0       test  Once again Mr. Costner has dragged out a movie...   neg\n",
       "1       test  This is an example of why the majority of acti...   neg\n",
       "2       test  First of all I hate those moronic rappers, who...   neg\n",
       "3       test  Not even the Beatles could write songs everyon...   neg\n",
       "4       test  Brass pictures (movies is not a fitting word f...   neg\n",
       "...      ...                                                ...   ...\n",
       "49995  train  Seeing as the vote average was pretty low, and...   pos\n",
       "49996  train  The plot had some wretched, unbelievable twist...   pos\n",
       "49997  train  I am amazed at how this movie(and most others ...   pos\n",
       "49998  train  A Christmas Together actually came before my t...   pos\n",
       "49999  train  Working-class romantic drama from director Mar...   pos\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "- Data Cleaning - Removiing punctuation symbols and removing numbers and converting text to lowercase\n",
    "- Tokenization - Essentially basic of splitting the data with space\n",
    "- Stop Words Removal\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "### 1. Removing punctuation \n",
    "### 2. Removing numbers\n",
    "### 3. Removing html tags\n",
    "### 4. Removing urls\n",
    "### 6. Converting the text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:19.292961Z",
     "iopub.status.busy": "2022-04-09T14:00:19.292382Z",
     "iopub.status.idle": "2022-04-09T14:00:19.299492Z",
     "shell.execute_reply": "2022-04-09T14:00:19.298901Z",
     "shell.execute_reply.started": "2022-04-09T14:00:19.292918Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(review):\n",
    "    return re.sub(r'[^\\w\\s]', \"\", review)\n",
    "\n",
    "def remove_numbers(review):\n",
    "    return re.sub(r'[\\d+]', \"\", review)\n",
    "\n",
    "def remove_html_tags(review):\n",
    "    \"\"\"\n",
    "        This takes care of the html tags as well as &nsbm similar characters\n",
    "        which are not specifically enclosed in html tags\n",
    "    \"\"\"  \n",
    "    c_rule = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    return re.sub(c_rule,'', review)\n",
    "\n",
    "def remove_urls(review):\n",
    "    return re.sub('https://.*', '', review)\n",
    "\n",
    "\n",
    "def convert_to_lowercase(review):\n",
    "    return review.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>train</td>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>train</td>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>train</td>\n",
       "      <td>I am amazed at how this movie(and most others ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>train</td>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>train</td>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                             review label\n",
       "0       test  Once again Mr. Costner has dragged out a movie...   neg\n",
       "1       test  This is an example of why the majority of acti...   neg\n",
       "2       test  First of all I hate those moronic rappers, who...   neg\n",
       "3       test  Not even the Beatles could write songs everyon...   neg\n",
       "4       test  Brass pictures (movies is not a fitting word f...   neg\n",
       "...      ...                                                ...   ...\n",
       "49995  train  Seeing as the vote average was pretty low, and...   pos\n",
       "49996  train  The plot had some wretched, unbelievable twist...   pos\n",
       "49997  train  I am amazed at how this movie(and most others ...   pos\n",
       "49998  train  A Christmas Together actually came before my t...   pos\n",
       "49999  train  Working-class romantic drama from director Mar...   pos\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:19.300988Z",
     "iopub.status.busy": "2022-04-09T14:00:19.300651Z",
     "iopub.status.idle": "2022-04-09T14:00:24.679175Z",
     "shell.execute_reply": "2022-04-09T14:00:24.678361Z",
     "shell.execute_reply.started": "2022-04-09T14:00:19.300961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 s, sys: 28.2 ms, total: 1.94 s\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Applying data cleaning\n",
    "full_dataset[\"review\"] = full_dataset.review.apply(remove_punctuation)\n",
    "full_dataset[\"review\"] = full_dataset.review.apply(remove_numbers)\n",
    "full_dataset[\"review\"] = full_dataset.review.apply(remove_html_tags)\n",
    "full_dataset[\"review\"] = full_dataset.review.apply(remove_urls)\n",
    "\n",
    "full_dataset[\"review\"] = full_dataset.review.apply(convert_to_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>once again mr costner has dragged out a movie ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>this is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>first of all i hate those moronic rappers who ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>not even the beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>train</td>\n",
       "      <td>seeing as the vote average was pretty low and ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>train</td>\n",
       "      <td>the plot had some wretched unbelievable twists...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>train</td>\n",
       "      <td>i am amazed at how this movieand most others h...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>train</td>\n",
       "      <td>a christmas together actually came before my t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>train</td>\n",
       "      <td>workingclass romantic drama from director mart...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                             review label\n",
       "0       test  once again mr costner has dragged out a movie ...   neg\n",
       "1       test  this is an example of why the majority of acti...   neg\n",
       "2       test  first of all i hate those moronic rappers who ...   neg\n",
       "3       test  not even the beatles could write songs everyon...   neg\n",
       "4       test  brass pictures movies is not a fitting word fo...   neg\n",
       "...      ...                                                ...   ...\n",
       "49995  train  seeing as the vote average was pretty low and ...   pos\n",
       "49996  train  the plot had some wretched unbelievable twists...   pos\n",
       "49997  train  i am amazed at how this movieand most others h...   pos\n",
       "49998  train  a christmas together actually came before my t...   pos\n",
       "49999  train  workingclass romantic drama from director mart...   pos\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:25.356341Z",
     "iopub.status.busy": "2022-04-09T14:00:25.356128Z",
     "iopub.status.idle": "2022-04-09T14:00:25.363875Z",
     "shell.execute_reply": "2022-04-09T14:00:25.363258Z",
     "shell.execute_reply.started": "2022-04-09T14:00:25.356316Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting the stopwords list\n",
    "stopwords_list = set(stopwords.words(\"english\"))\n",
    "def apply_tokenization_and_remove_stopwords(review):\n",
    "    # Applying tokenization\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    # applying removal of stopwords\n",
    "    review_no_stopwords = [word for word in tokens if word not in stopwords_list]\n",
    "    return \" \".join(review_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:00:25.365350Z",
     "iopub.status.busy": "2022-04-09T14:00:25.364865Z",
     "iopub.status.idle": "2022-04-09T14:01:17.407316Z",
     "shell.execute_reply": "2022-04-09T14:01:17.406454Z",
     "shell.execute_reply.started": "2022-04-09T14:00:25.365307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing stop words from the text\n",
    "full_dataset[\"review\"] = full_dataset.review.apply(apply_tokenization_and_remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:01:17.409523Z",
     "iopub.status.busy": "2022-04-09T14:01:17.408951Z",
     "iopub.status.idle": "2022-04-09T14:01:18.570955Z",
     "shell.execute_reply": "2022-04-09T14:01:18.570101Z",
     "shell.execute_reply.started": "2022-04-09T14:01:17.409485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting the text to root word - eg. low, lower, lowest converted to low\n",
    "def apply_lemmatization(review):\n",
    "    lemmatized_review = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    for w in tokens:\n",
    "        lemmatized_review.append(lemmatizer.lemmatize(w))\n",
    "    return \" \".join(lemmatized_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:01:18.572923Z",
     "iopub.status.busy": "2022-04-09T14:01:18.572393Z",
     "iopub.status.idle": "2022-04-09T14:02:16.171991Z",
     "shell.execute_reply": "2022-04-09T14:02:16.170331Z",
     "shell.execute_reply.started": "2022-04-09T14:01:18.572865Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying lemmatization\n",
    "full_dataset[\"review\"] = full_dataset.review.apply(apply_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>mr costner dragged movie far longer necessary ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>example majority action film generic boring th...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>first hate moronic rapper couldnt act gun pres...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>even beatles could write song everyone liked a...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>brass picture movie fitting word really somewh...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>train</td>\n",
       "      <td>seeing vote average pretty low fact clerk vide...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>train</td>\n",
       "      <td>plot wretched unbelievable twist however chemi...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>train</td>\n",
       "      <td>amazed movieand others average star lower crap...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>train</td>\n",
       "      <td>christmas together actually came time ive rais...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>train</td>\n",
       "      <td>workingclass romantic drama director martin ri...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                             review label\n",
       "0       test  mr costner dragged movie far longer necessary ...   neg\n",
       "1       test  example majority action film generic boring th...   neg\n",
       "2       test  first hate moronic rapper couldnt act gun pres...   neg\n",
       "3       test  even beatles could write song everyone liked a...   neg\n",
       "4       test  brass picture movie fitting word really somewh...   neg\n",
       "...      ...                                                ...   ...\n",
       "49995  train  seeing vote average pretty low fact clerk vide...   pos\n",
       "49996  train  plot wretched unbelievable twist however chemi...   pos\n",
       "49997  train  amazed movieand others average star lower crap...   pos\n",
       "49998  train  christmas together actually came time ive rais...   pos\n",
       "49999  train  workingclass romantic drama director martin ri...   pos\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:02:16.173453Z",
     "iopub.status.busy": "2022-04-09T14:02:16.173168Z",
     "iopub.status.idle": "2022-04-09T14:02:16.179968Z",
     "shell.execute_reply": "2022-04-09T14:02:16.179213Z",
     "shell.execute_reply.started": "2022-04-09T14:02:16.173415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape before removing duplicates\n",
    "full_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:02:16.181516Z",
     "iopub.status.busy": "2022-04-09T14:02:16.181280Z",
     "iopub.status.idle": "2022-04-09T14:02:16.331138Z",
     "shell.execute_reply": "2022-04-09T14:02:16.330315Z",
     "shell.execute_reply.started": "2022-04-09T14:02:16.181489Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping duplicates\n",
    "full_dataset = full_dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:02:16.332640Z",
     "iopub.status.busy": "2022-04-09T14:02:16.332391Z",
     "iopub.status.idle": "2022-04-09T14:02:16.337869Z",
     "shell.execute_reply": "2022-04-09T14:02:16.337111Z",
     "shell.execute_reply.started": "2022-04-09T14:02:16.332610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49700, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape after removing duplicates\n",
    "full_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating the data into training dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:02:16.339381Z",
     "iopub.status.busy": "2022-04-09T14:02:16.339136Z",
     "iopub.status.idle": "2022-04-09T14:02:16.366946Z",
     "shell.execute_reply": "2022-04-09T14:02:16.366344Z",
     "shell.execute_reply.started": "2022-04-09T14:02:16.339353Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = full_dataset[full_dataset.type == \"train\"]\n",
    "test_dataset = full_dataset[full_dataset.type == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:02:16.368344Z",
     "iopub.status.busy": "2022-04-09T14:02:16.367836Z",
     "iopub.status.idle": "2022-04-09T14:02:16.373290Z",
     "shell.execute_reply": "2022-04-09T14:02:16.372608Z",
     "shell.execute_reply.started": "2022-04-09T14:02:16.368314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24902, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking rows and columns of train dataset\n",
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:02:16.374812Z",
     "iopub.status.busy": "2022-04-09T14:02:16.374547Z",
     "iopub.status.idle": "2022-04-09T14:02:16.383919Z",
     "shell.execute_reply": "2022-04-09T14:02:16.383293Z",
     "shell.execute_reply.started": "2022-04-09T14:02:16.374785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24798, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking rows and columns of test dataset\n",
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the label pos neg values to 1 and 0 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:02:16.385537Z",
     "iopub.status.busy": "2022-04-09T14:02:16.385113Z",
     "iopub.status.idle": "2022-04-09T14:02:16.405305Z",
     "shell.execute_reply": "2022-04-09T14:02:16.404758Z",
     "shell.execute_reply.started": "2022-04-09T14:02:16.385509Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset[\"label\"] = np.where(train_dataset[\"label\"] == \"pos\", 1, 0)\n",
    "test_dataset[\"label\"] = np.where(test_dataset[\"label\"] == \"pos\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:02:16.406678Z",
     "iopub.status.busy": "2022-04-09T14:02:16.406467Z",
     "iopub.status.idle": "2022-04-09T14:02:16.413616Z",
     "shell.execute_reply": "2022-04-09T14:02:16.412856Z",
     "shell.execute_reply.started": "2022-04-09T14:02:16.406653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taking the list of independent variable for training set\n",
    "X = train_dataset.review.to_list()\n",
    "# Taking the list of independent variable for test set\n",
    "X_test = test_dataset.review.to_list()\n",
    "\n",
    "# Choosing the target variable\n",
    "y = train_dataset.label.to_list()\n",
    "\n",
    "# actual y values\n",
    "y_test = test_dataset.label.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Naive Bayes Classifier \n",
    "- ## Since we are finding the binary classification i.e the sentimental analysis,We will be using multinomial Naive Bayes to get values in respect with classes (0 and 1)\n",
    "\n",
    "- **NOTE** First uncomment the two lines suggested in the predict method of CustomMultinomialNB class. Later when sanity check is done, comment it again and run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:29:54.491700Z",
     "iopub.status.busy": "2022-04-09T14:29:54.490933Z",
     "iopub.status.idle": "2022-04-09T14:29:54.517450Z",
     "shell.execute_reply": "2022-04-09T14:29:54.516309Z",
     "shell.execute_reply.started": "2022-04-09T14:29:54.491651Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomMultinomialNB:\n",
    "    \n",
    "    def __init__(self, k=1):\n",
    "        self.k = k\n",
    "        self.neg_prior_probability = 0\n",
    "        self.pos_prior_probability = 0\n",
    "        self.total_words_pos_class = 0\n",
    "        self.total_words_neg_class = 0\n",
    "        self.cond_prob_word_with_class = {}\n",
    "        self.vocab = []\n",
    "        \n",
    "        \n",
    "    def prior_probabilities(self, X, y):\n",
    "        \n",
    "        # Calculate the total number of documents (in this case reviews)\n",
    "        total_number_of_documents = len(X)\n",
    "        \n",
    "        # Calculate the number of each class in all the documents\n",
    "        num_of_pos_class_in_docs = num_of_neg_class_in_docs = 0\n",
    "        \n",
    "        for i in y:\n",
    "            # if i is 1\n",
    "            if i:\n",
    "                num_of_pos_class_in_docs += 1\n",
    "            else:\n",
    "                num_of_neg_class_in_docs += 1\n",
    "        \n",
    "        # Calculating prior probability for each class\n",
    "        pos_prior_prob = num_of_pos_class_in_docs / total_number_of_documents\n",
    "        neg_prior_prob = num_of_neg_class_in_docs / total_number_of_documents\n",
    "        \n",
    "        return neg_prior_prob, pos_prior_prob\n",
    "    \n",
    "    \n",
    "    def get_count_words_with_class(self, X, y):\n",
    "        # {word: [count of this word in neg class, count of this word in pos class]}\n",
    "        counts = {}\n",
    "        for idx, review in enumerate(X):\n",
    "            current_sentiment = y[idx]\n",
    "            for w in review.split():\n",
    "                if w not in counts:\n",
    "                    counts[w] = [0,0]\n",
    "                counts[w][current_sentiment] += 1\n",
    "        \n",
    "        return counts\n",
    "    \n",
    "    \n",
    "    def generate_vocabulary(self, word_dict):\n",
    "        return [w for w in word_dict]\n",
    "    \n",
    "    def get_total_words_each_class(self, word_dict):\n",
    "        pos_count = neg_count = 0\n",
    "        for key, val in word_dict.items():\n",
    "            neg_count += val[0]\n",
    "            pos_count += val[1]\n",
    "        \n",
    "        return neg_count, pos_count\n",
    "    \n",
    "    # maps the likelihood of each word with class\n",
    "    def get_conditional_probabilities_with_class(self, counts):\n",
    "        word_prob_dict = {}\n",
    "        # for each word return word, p(w | 0), p(w | 1)\n",
    "        for word in counts:\n",
    "            prob_word_neg = (counts[word][0] + self.k) / (self.total_words_neg_class + (len(self.vocab)*self.k))\n",
    "            prob_word_pos = (counts[word][1] + self.k) / (self.total_words_pos_class + (len(self.vocab)*self.k))\n",
    "            word_prob_dict.update(\n",
    "                {\n",
    "                    word: [prob_word_neg, prob_word_pos]\n",
    "                }\n",
    "            )\n",
    "        return word_prob_dict\n",
    "     \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Step 1: Get the prior probabilities\n",
    "        self.neg_prior_probability, self.pos_prior_probability = self.prior_probabilities(X, y)\n",
    "        \n",
    "        # Step 2: count words with each class\n",
    "        count_words_with_class = self.get_count_words_with_class(X, y)\n",
    "        \n",
    "        # Step 3: Generating vocab\n",
    "        self.vocab = self.generate_vocabulary(count_words_with_class)\n",
    "        \n",
    "        # Step 4: Count total words in each class\n",
    "        self.total_words_neg_class, self.total_words_pos_class = self.get_total_words_each_class(count_words_with_class)\n",
    "        \n",
    "        # Step 3: Counting Likelihood of each word and generating a dict\n",
    "        self.cond_prob_word_with_class = self.get_conditional_probabilities_with_class(count_words_with_class)\n",
    "        \n",
    "    \n",
    "    def predict(self, test):\n",
    "        y_pred = []\n",
    "        \n",
    "        # Iterate through each word\n",
    "        for document in test:\n",
    "            log_prob_neg = log_prob_pos = 0\n",
    "            \n",
    "            tokens = document.split()\n",
    "            # if word in conditional probability dict then add the log of probabilities\n",
    "            for word in tokens:\n",
    "                if word in self.cond_prob_word_with_class:\n",
    "                    prob_word_neg, prob_word_pos = self.cond_prob_word_with_class[word]\n",
    "                    log_prob_neg += np.log(prob_word_neg)\n",
    "                    log_prob_pos += np.log(prob_word_pos)\n",
    "    \n",
    "            # Converting the log values back to original values using np.exp method\n",
    "            # getting the predicted probabilities for each class \n",
    "            neg_pred = self.neg_prior_probability * np.exp(log_prob_neg)\n",
    "            pos_pred = self.pos_prior_probability * np.exp(log_prob_pos)\n",
    "            \n",
    "            # Uncomment below code when you want to run sanity check for example 1\n",
    "            # print(f\"Probability for chinese prediction : {pos_pred}\")\n",
    "            # print(f\"Probability for japanese prediction : {neg_pred}\")\n",
    "            \n",
    "            \n",
    "            if neg_pred >= pos_pred:\n",
    "                y_pred.append(0)\n",
    "            else:\n",
    "                y_pred.append(1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check with two Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating the instance of Multinomial NB class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:29:58.390915Z",
     "iopub.status.busy": "2022-04-09T14:29:58.390484Z",
     "iopub.status.idle": "2022-04-09T14:29:58.426447Z",
     "shell.execute_reply": "2022-04-09T14:29:58.425614Z",
     "shell.execute_reply.started": "2022-04-09T14:29:58.390879Z"
    }
   },
   "outputs": [],
   "source": [
    "nb = CustomMultinomialNB(k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model on some examples dataset \n",
    "- This is done to see if the classifier predicts the correct probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_example = [\n",
    "    \"Chinese Beijing Chinese\", \n",
    "    \"Chinese Chinese Shanghai\",\n",
    "    \"Chinese Macao\",\n",
    "    \"Tokyo Japan Chinese\"\n",
    "]\n",
    "y_example = [1, 1, 1, 0]\n",
    "X_test_example = [\"Chinese Chinese Chinese Tokyo Japan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **NOTE** For this example the classes are chinese = 1 and japanese = 0\n",
    "- Also the Probability of predicting chinese is 0.00030121377997263015\n",
    "- and Probability of predicting japanese is 0.00013548070246744218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:12:23.829585Z",
     "iopub.status.busy": "2022-04-09T14:12:23.829016Z",
     "iopub.status.idle": "2022-04-09T14:12:25.657233Z",
     "shell.execute_reply": "2022-04-09T14:12:25.656320Z",
     "shell.execute_reply.started": "2022-04-09T14:12:23.829532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 µs, sys: 1 µs, total: 19 µs\n",
      "Wall time: 19.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training the model\n",
    "nb.fit(X_example, y_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the class for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:12:31.261564Z",
     "iopub.status.busy": "2022-04-09T14:12:31.261024Z",
     "iopub.status.idle": "2022-04-09T14:12:41.062844Z",
     "shell.execute_reply": "2022-04-09T14:12:41.061950Z",
     "shell.execute_reply.started": "2022-04-09T14:12:31.261516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: Chinese\n"
     ]
    }
   ],
   "source": [
    "y_pred_example = nb.predict(X_test_example)\n",
    "if y_pred_example[0]:\n",
    "    print(\"Predicted Class: Chinese\")\n",
    "else:\n",
    "    print(\"Predicted Class: Japanese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Looking at the probabilities and the prediction we can say that the sanity check works correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model on real training dataset\n",
    "- **NOTE** GO back to the class MultinomialNB and comment the two lines in predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the instance \n",
    "nb = CustomMultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 619 ms, sys: 9.28 ms, total: 628 ms\n",
      "Wall time: 627 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.41 s, sys: 3.71 ms, total: 2.41 s\n",
      "Wall time: 2.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predicting on the test set\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics to evaluate performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:12:44.111670Z",
     "iopub.status.busy": "2022-04-09T14:12:44.111047Z",
     "iopub.status.idle": "2022-04-09T14:12:44.117903Z",
     "shell.execute_reply": "2022-04-09T14:12:44.117182Z",
     "shell.execute_reply.started": "2022-04-09T14:12:44.111631Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the accuracy and f1 score from scratch\n",
    "def get_accuracy_and_f1_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score_scratch = ((2 * precision * recall) / (precision + recall))\n",
    "    accuracy_score_scratch = (tp + tn) / (tp+tn+fp+fn)\n",
    "    return f1_score_scratch, accuracy_score_scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:12:46.736000Z",
     "iopub.status.busy": "2022-04-09T14:12:46.735409Z",
     "iopub.status.idle": "2022-04-09T14:12:46.765783Z",
     "shell.execute_reply": "2022-04-09T14:12:46.765116Z",
     "shell.execute_reply.started": "2022-04-09T14:12:46.735964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.552688530048277\n",
      "Accuracy Score: 0.674933462375998\n"
     ]
    }
   ],
   "source": [
    "f1_score_scratch, accuracy_score_scratch = get_accuracy_and_f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1_score_scratch}\")\n",
    "print(f\"Accuracy Score: {accuracy_score_scratch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check with sklearn metrics methods `f1_score` and `accuracy_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T14:14:12.869319Z",
     "iopub.status.busy": "2022-04-09T14:14:12.869047Z",
     "iopub.status.idle": "2022-04-09T14:14:12.943747Z",
     "shell.execute_reply": "2022-04-09T14:14:12.942954Z",
     "shell.execute_reply.started": "2022-04-09T14:14:12.869294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.552688530048277\n",
      "Accuracy Score: 0.674933462375998\n"
     ]
    }
   ],
   "source": [
    "# Get the accuracy and f1 score from sklearn\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Note**: For checking if the f1 score and accuracy score is correct or not I applied sanity check with above code cell using the sklearn library \n",
    "- As we can see that both the f1 score and accuracy using both methods gives us the same score. That means the sanity check is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above code cell we can say that f1 score and accuracy score is decent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
